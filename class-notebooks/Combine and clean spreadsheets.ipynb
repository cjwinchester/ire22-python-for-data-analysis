{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3ffa8e01",
   "metadata": {},
   "source": [
    "# Combine and clean spreadsheets\n",
    "\n",
    "This notebook has Python code to parse, combine and clean the spreadsheets downloaded from [the FAA's website showing laser pointer incidents around the U.S.](https://www.faa.gov/about/initiatives/lasers/laws) The goal is to build a workflow that can be re-run any time the FAA releases new data and produce the same output: a single file, `faa-laser-incidents.csv`, that lands in the `class-notebooks` directory.\n",
    "\n",
    "The process involves loading each spreadsheet into a pandas dataframe while conditionally applying some code to standardize its structure, then combining those separate dataframes into a single dataframe, then finally applying some code to clean up some of the data.\n",
    "\n",
    "\n",
    "### One quick note\n",
    "The process of deciding how each spreadsheet needs to be loaded and cleaned was iterative -- at first trying some sensible defaults to see what worked and what didn't, adjusting the process accordingly, testing changes on sample data before applying them to the entire dataset, and generally seeing how everything needed to fit together to build a common dataset. \n",
    "\n",
    "It took a couple of hours to get my head around the various problems with each spreadsheet and how things needed to fit together, but this two-steps-forward-one-step-back approach is pretty typical for sussing out data problems and then writing code to fix them.\n",
    "\n",
    "It was only later, after I was more sure that I had a handle on things, that I thought more holistically about how the whole workflow should run and went back in and cleaned up various bits of test code, rearranged things, etc. (All of which to say: The process of developing a data workflow of any complexity is rarely linear.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20dc42f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import from the Python standard library\n",
    "import datetime\n",
    "\n",
    "# import from a local python file\n",
    "from fixes import fixes_injury, fixes_states, fixes_colors, problem_timestrings, problem_datestrings\n",
    "\n",
    "# import from a package installed separately into a virtual environment\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "771dc37f",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "these are the common headers we'll be using for every year's dataframe -- I worked this out\n",
    "by loading each spreadsheet into a dataframe and then looking at the .columns attribute\n",
    "of each dataframe, then figured out which ones needed to be renamed, ignored, etc.\n",
    "'''\n",
    "\n",
    "headers_main = [\n",
    "    'Incident Date',\n",
    "    'Incident Time',\n",
    "    'Flight ID',\n",
    "    'Aircraft',\n",
    "    'Altitude',\n",
    "    'Airport',\n",
    "    'Laser Color',\n",
    "    'Injury',\n",
    "    'City',\n",
    "    'State'\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c09454c",
   "metadata": {},
   "source": [
    "### Load each year's spreadsheet individually\n",
    "\n",
    "There's a little overlap, but each sheet needs something slightly different on import, so you need to express that in code somehow."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10ccbd10",
   "metadata": {},
   "outputs": [],
   "source": [
    "# mapping key/value pairs of years to the files\n",
    "xls_files = {\n",
    "    '2010-2014': '../data/laser_incidents_2010-2014.xls',\n",
    "    '2015': '../data/reported_laser_illumination_incidents_CY_2015.xls',\n",
    "    '2016': '../data/reported_laser_illumination_incidents_CY_2016.xlsx',\n",
    "    '2017': '../data/reported_laser_illumination_incidents_CY_2017.xlsx',\n",
    "    '2018': '../data/Laser_Report_2018_final.xlsx',\n",
    "    '2019': '../data/Laser_Report_2019_final.xlsx',\n",
    "    '2020': '../data/Laser_Report_2020.xlsx',\n",
    "    '2021': '../data/Laser-Report-2021-FINAL.xlsx',\n",
    "    '2022': '../data/Laser-Report-2022-through-05-31.xlsx'   \n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4513d15",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2010-2014 file needs a looooooot of work to standardize things\n",
    "\n",
    "# sure, why not slightly rename your columns every single year\n",
    "xls_1014_columns = {\n",
    "    '2010': [\n",
    "        'DATE',\n",
    "        'TIME (UTC)',\n",
    "        'ACID',\n",
    "        'TYPE A/C',\n",
    "        'ALT',\n",
    "        'MAJOR CITY',\n",
    "        'COLOR',\n",
    "        'Injury Reported',\n",
    "        'CITY',\n",
    "        'STATE'\n",
    "    ],\n",
    "    '2011': [\n",
    "        'DATE',\n",
    "        'TIME (UTC)',\n",
    "        'AC/ID',\n",
    "        'TYPE A/C',\n",
    "        'ALT',\n",
    "        'MAJOR CITY',\n",
    "        'COLOR',\n",
    "        'Injury Reported',\n",
    "        'CITY',\n",
    "        'STATE'\n",
    "    ],\n",
    "    '2012': [\n",
    "        'DATE',\n",
    "        'TIME (UTC)',\n",
    "        'Aircraft ID',\n",
    "        'TYPE A/C',\n",
    "        'ALT',\n",
    "        'MAJOR CITY',\n",
    "        'COLOR',\n",
    "        'Injury Reported',\n",
    "        'CITY',\n",
    "        'STATE'\n",
    "    ],\n",
    "    '2013': [\n",
    "        'DATE',\n",
    "        'TIME (UTC)',\n",
    "        'Aircraft ID',\n",
    "        'TYPE A/C',\n",
    "        'ALT',\n",
    "        'MAJOR CITY',\n",
    "        'COLOR',\n",
    "        'Injury Reported',\n",
    "        'CITY',\n",
    "        'STATE'\n",
    "    ],\n",
    "    '2014': [\n",
    "        'DATE',\n",
    "        'TIME (UTC)',\n",
    "        'Aircraft ID',\n",
    "        'TYPE A/C',\n",
    "        'ALT',\n",
    "        'MAJOR CITY',\n",
    "        'COLOR',\n",
    "        'Injury Reported',\n",
    "        'CITY',\n",
    "        'STATE'\n",
    "    ]\n",
    "}\n",
    "\n",
    "# we need to look at each sheet individually, so first we need to load it as an ExcelFile object\n",
    "# https://pandas.pydata.org/docs/reference/api/pandas.ExcelFile.parse.html\n",
    "xls_14 = pd.ExcelFile(xls_files['2010-2014'])\n",
    "\n",
    "# create an empty data frame to start\n",
    "df_14 = pd.DataFrame()\n",
    "\n",
    "# loop over the years based on how the sheets are named: `Laser Report {year}`\n",
    "# from 2010 - 2014\n",
    "# (the range function is not inclusive on the back end)\n",
    "# \n",
    "for year in range(2010, 2015):\n",
    "    \n",
    "    # create a new dataframe from this particular worksheet\n",
    "    # and use the columns we mapped out above\n",
    "    new_df = pd.read_excel(\n",
    "        xls_14,\n",
    "        f'Laser Report {year}',\n",
    "        usecols=xls_1014_columns[str(year)]\n",
    "    )\n",
    "    \n",
    "    # rename the columns to our standard values above\n",
    "    new_df.rename(columns=dict(zip(xls_1014_columns[str(year)], headers_main)), inplace=True)\n",
    "    \n",
    "    # add it to the main df\n",
    "    df_14 = pd.concat([df_14, new_df])\n",
    "\n",
    "# kill out errant \"Total\" rows\n",
    "df_14 = df_14[df_14['Flight ID'].str.contains('Total', na=False) == False]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3108b9d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_14.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc19cd71",
   "metadata": {},
   "outputs": [],
   "source": [
    "# lop off two crufty columns at the end\n",
    "df_15 = pd.read_excel(\n",
    "    xls_files['2015'],\n",
    "    usecols=range(10),\n",
    "    names=headers_main\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5851fbbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_15.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10341ca4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# standardize column names\n",
    "df_16 = pd.read_excel(\n",
    "    xls_files['2016'],\n",
    "    usecols=headers_main\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "addc1db4",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_16.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2838b76e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# standardize column names\n",
    "df_17 = pd.read_excel(\n",
    "    xls_files['2017'],\n",
    "    names=headers_main\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4bcec352",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_17.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12dd713b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# standardize column names\n",
    "df_18 = pd.read_excel(\n",
    "    xls_files['2018'],\n",
    "    names=headers_main\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6fa2d00",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_18.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c560ee96",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_19 = pd.read_excel(\n",
    "    xls_files['2019'],\n",
    "    names=headers_main\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abca3d26",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_19.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56c7315b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# standardize column names\n",
    "df_20 = pd.read_excel(\n",
    "    xls_files['2020'],\n",
    "    names=headers_main\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec91c86c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_20.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79434a06",
   "metadata": {},
   "outputs": [],
   "source": [
    "# skip crufty first row and standardize column names\n",
    "df_21 = pd.read_excel(\n",
    "    xls_files['2021'],\n",
    "    skiprows=1,\n",
    "    names=headers_main\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3344cbfe",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_21.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e27acd30",
   "metadata": {},
   "outputs": [],
   "source": [
    "# standardize column names\n",
    "df_22 = pd.read_excel(\n",
    "    xls_files['2022'],\n",
    "    names=headers_main\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c004f590",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_22.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c9f9dea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load all of these dataframes into a list for later convenience\n",
    "dfs = [\n",
    "    df_14,\n",
    "    df_15,\n",
    "    df_16,\n",
    "    df_17,\n",
    "    df_18,\n",
    "    df_19,\n",
    "    df_20,\n",
    "    df_21,\n",
    "    df_22\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c9d476a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# check that all column values are the same\n",
    "[list(x.columns) == list(dfs[0].columns) for x in dfs]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f430f1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# a custom function to mash together the date and time columns into a proper datetime\n",
    "def get_utc_datetime(row):\n",
    "    \n",
    "    # grab the date\n",
    "    datestr = row['Incident Date']\n",
    "    \n",
    "    # check to see if that date is on our list of problems\n",
    "    if datestr in problem_datestrings or not datestr:\n",
    "        return datetime.datetime(0, 0, 0, 0, 0, 0)\n",
    "    \n",
    "    # make it an actual date, not a datetime\n",
    "    date = datestr.date()\n",
    "\n",
    "    # grab the time\n",
    "    time = row['Incident Time']\n",
    "    \n",
    "    # check to see if this value is on our problem list\n",
    "    if not time or time in problem_timestrings:\n",
    "        time = '0000'\n",
    "    else:\n",
    "        try:\n",
    "            \n",
    "            # pad it out to four digits\n",
    "            time = str(int(row['Incident Time'])).zfill(4).strip()\n",
    "        except ValueError:\n",
    "            time = '0000'\n",
    "    \n",
    "    # assemble a UTC date (confirmed w/ FAA press human)\n",
    "    datetime_str = f'{date}T{time[:2]}:{time[2:]}:00Z'\n",
    "    return datetime.datetime.strptime(datetime_str,'%Y-%m-%dT%H:%M:%SZ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71c6d9fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# loop over the data frames and apply the function\n",
    "for df in dfs:\n",
    "    \n",
    "    # use the function to generate a UTC datetime\n",
    "    df['datetime_utc'] = df.apply(get_utc_datetime, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b2d596e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# smush all the data frames together into one\n",
    "df = pd.concat(dfs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f6a66eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# extract the year into a new column\n",
    "# https://pandas.pydata.org/docs/reference/api/pandas.Series.dt.html\n",
    "df['year'] = df['Incident Date'].dt.year"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e4c554e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# check your work\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffb5cb6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5aa04888",
   "metadata": {},
   "outputs": [],
   "source": [
    "# how many records altogether?\n",
    "len(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a524e214",
   "metadata": {},
   "outputs": [],
   "source": [
    "# check to see how dirty the Injury column is\n",
    "list(df.Injury.unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98db53d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# strip whitespace and upcase\n",
    "df.Injury = df.Injury.str.upper().str.strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84020d2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# now see unique values\n",
    "sorted(set([x for x in list(df['Injury'].unique()) if pd.isnull(x) == False]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac7cd0f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# what's the deal with this one?\n",
    "df[df.Injury == 'GREEN']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb33896c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# apply a lambda function to look up the value (clean) by the key (messy)\n",
    "df['injury_clean'] = df.apply(lambda row: fixes_injury.get(row['Injury'], row['Injury']), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1dbe815c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.injury_clean.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd112e2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "sorted(df.year.unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9956e9e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# check flight ID\n",
    "df['Flight ID'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f43b685c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# standardize state values\n",
    "df['State'] = df['State'].str.upper().str.strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f6dcb7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# check the list\n",
    "sorted(set([x for x in list(df['State'].unique()) if pd.isnull(x) == False]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae0db4d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# apply a lambda function to look up the value (clean) by the key (messy)\n",
    "df['state_clean'] = df.apply(lambda row: fixes_states.get(row['State'], row['State']), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4c85f1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a801846c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.state_clean.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d77002f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# same routine with the laser color\n",
    "df['Laser Color'] = df['Laser Color'].str.strip().str.lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a54b656",
   "metadata": {},
   "outputs": [],
   "source": [
    "sorted(set([x for x in list(df['Laser Color'].unique()) if pd.isnull(x) == False]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b25826b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# apply a lambda function to look up the value (clean) by the key (messy)\n",
    "df['colors_clean'] = df.apply(lambda row: fixes_colors.get(row['Laser Color'], row['Laser Color']), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3bb43f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02b41729",
   "metadata": {},
   "outputs": [],
   "source": [
    "# export to CSV\n",
    "df.to_csv('faa-laser-incidents.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
